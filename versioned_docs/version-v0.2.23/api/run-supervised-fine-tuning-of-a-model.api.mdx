---
id: run-supervised-fine-tuning-of-a-model
title: "Run supervised fine-tuning of a model."
description: "Run supervised fine-tuning of a model."
sidebar_label: "Run supervised fine-tuning of a model."
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/api/llama-stack-specification
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Run supervised fine-tuning of a model."}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v1alpha/post-training/supervised-fine-tune"}
  context={"endpoint"}
>

</MethodEndpoint>



Run supervised fine-tuning of a model.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[]}
>

</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"content":{"application/json":{"schema":{"type":"object","properties":{"job_uuid":{"type":"string","description":"The UUID of the job to create."},"training_config":{"description":"The training configuration.","type":"object","properties":{"n_epochs":{"type":"integer","description":"Number of training epochs to run"},"max_steps_per_epoch":{"type":"integer","default":1,"description":"Maximum number of steps to run per epoch"},"gradient_accumulation_steps":{"type":"integer","default":1,"description":"Number of steps to accumulate gradients before updating"},"max_validation_steps":{"type":"integer","default":1,"description":"(Optional) Maximum number of validation steps per epoch"},"data_config":{"description":"(Optional) Configuration for data loading and formatting","type":"object","properties":{"dataset_id":{"type":"string","description":"Unique identifier for the training dataset"},"batch_size":{"type":"integer","description":"Number of samples per training batch"},"shuffle":{"type":"boolean","description":"Whether to shuffle the dataset during training"},"data_format":{"description":"Format of the dataset (instruct or dialog)","type":"string","enum":["instruct","dialog"],"title":"DatasetFormat"},"validation_dataset_id":{"type":"string","description":"(Optional) Unique identifier for the validation dataset"},"packed":{"type":"boolean","default":false,"description":"(Optional) Whether to pack multiple samples into a single sequence for efficiency"},"train_on_input":{"type":"boolean","default":false,"description":"(Optional) Whether to compute loss on input tokens as well as output tokens"}},"additionalProperties":false,"required":["dataset_id","batch_size","shuffle","data_format"],"title":"DataConfig"},"optimizer_config":{"description":"(Optional) Configuration for the optimization algorithm","type":"object","properties":{"optimizer_type":{"description":"Type of optimizer to use (adam, adamw, or sgd)","type":"string","enum":["adam","adamw","sgd"],"title":"OptimizerType"},"lr":{"type":"number","description":"Learning rate for the optimizer"},"weight_decay":{"type":"number","description":"Weight decay coefficient for regularization"},"num_warmup_steps":{"type":"integer","description":"Number of steps for learning rate warmup"}},"additionalProperties":false,"required":["optimizer_type","lr","weight_decay","num_warmup_steps"],"title":"OptimizerConfig"},"efficiency_config":{"description":"(Optional) Configuration for memory and compute optimizations","type":"object","properties":{"enable_activation_checkpointing":{"type":"boolean","default":false,"description":"(Optional) Whether to use activation checkpointing to reduce memory usage"},"enable_activation_offloading":{"type":"boolean","default":false,"description":"(Optional) Whether to offload activations to CPU to save GPU memory"},"memory_efficient_fsdp_wrap":{"type":"boolean","default":false,"description":"(Optional) Whether to use memory-efficient FSDP wrapping"},"fsdp_cpu_offload":{"type":"boolean","default":false,"description":"(Optional) Whether to offload FSDP parameters to CPU"}},"additionalProperties":false,"title":"EfficiencyConfig"},"dtype":{"type":"string","default":"bf16","description":"(Optional) Data type for model parameters (bf16, fp16, fp32)"}},"additionalProperties":false,"required":["n_epochs","max_steps_per_epoch","gradient_accumulation_steps"],"title":"TrainingConfig"},"hyperparam_search_config":{"type":"object","additionalProperties":{"oneOf":[{"type":"null"},{"type":"boolean"},{"type":"number"},{"type":"string"},{"type":"array"},{"type":"object"}]},"description":"The hyperparam search configuration."},"logger_config":{"type":"object","additionalProperties":{"oneOf":[{"type":"null"},{"type":"boolean"},{"type":"number"},{"type":"string"},{"type":"array"},{"type":"object"}]},"description":"The logger configuration."},"model":{"type":"string","description":"The model to fine-tune."},"checkpoint_dir":{"type":"string","description":"The directory to save checkpoint(s) to."},"algorithm_config":{"description":"The algorithm configuration.","oneOf":[{"type":"object","properties":{"type":{"type":"string","const":"LoRA","default":"LoRA","description":"Algorithm type identifier, always \"LoRA\""},"lora_attn_modules":{"type":"array","items":{"type":"string"},"description":"List of attention module names to apply LoRA to"},"apply_lora_to_mlp":{"type":"boolean","description":"Whether to apply LoRA to MLP layers"},"apply_lora_to_output":{"type":"boolean","description":"Whether to apply LoRA to output projection layers"},"rank":{"type":"integer","description":"Rank of the LoRA adaptation (lower rank = fewer parameters)"},"alpha":{"type":"integer","description":"LoRA scaling parameter that controls adaptation strength"},"use_dora":{"type":"boolean","default":false,"description":"(Optional) Whether to use DoRA (Weight-Decomposed Low-Rank Adaptation)"},"quantize_base":{"type":"boolean","default":false,"description":"(Optional) Whether to quantize the base model weights"}},"additionalProperties":false,"required":["type","lora_attn_modules","apply_lora_to_mlp","apply_lora_to_output","rank","alpha"],"title":"LoraFinetuningConfig","description":"Configuration for Low-Rank Adaptation (LoRA) fine-tuning."},{"type":"object","properties":{"type":{"type":"string","const":"QAT","default":"QAT","description":"Algorithm type identifier, always \"QAT\""},"quantizer_name":{"type":"string","description":"Name of the quantization algorithm to use"},"group_size":{"type":"integer","description":"Size of groups for grouped quantization"}},"additionalProperties":false,"required":["type","quantizer_name","group_size"],"title":"QATFinetuningConfig","description":"Configuration for Quantization-Aware Training (QAT) fine-tuning."}],"discriminator":{"propertyName":"type","mapping":{"LoRA":{"type":"object","properties":{"type":{"type":"string","const":"LoRA","default":"LoRA","description":"Algorithm type identifier, always \"LoRA\""},"lora_attn_modules":{"type":"array","items":{"type":"string"},"description":"List of attention module names to apply LoRA to"},"apply_lora_to_mlp":{"type":"boolean","description":"Whether to apply LoRA to MLP layers"},"apply_lora_to_output":{"type":"boolean","description":"Whether to apply LoRA to output projection layers"},"rank":{"type":"integer","description":"Rank of the LoRA adaptation (lower rank = fewer parameters)"},"alpha":{"type":"integer","description":"LoRA scaling parameter that controls adaptation strength"},"use_dora":{"type":"boolean","default":false,"description":"(Optional) Whether to use DoRA (Weight-Decomposed Low-Rank Adaptation)"},"quantize_base":{"type":"boolean","default":false,"description":"(Optional) Whether to quantize the base model weights"}},"additionalProperties":false,"required":["type","lora_attn_modules","apply_lora_to_mlp","apply_lora_to_output","rank","alpha"],"title":"LoraFinetuningConfig","description":"Configuration for Low-Rank Adaptation (LoRA) fine-tuning."},"QAT":{"type":"object","properties":{"type":{"type":"string","const":"QAT","default":"QAT","description":"Algorithm type identifier, always \"QAT\""},"quantizer_name":{"type":"string","description":"Name of the quantization algorithm to use"},"group_size":{"type":"integer","description":"Size of groups for grouped quantization"}},"additionalProperties":false,"required":["type","quantizer_name","group_size"],"title":"QATFinetuningConfig","description":"Configuration for Quantization-Aware Training (QAT) fine-tuning."}}},"title":"AlgorithmConfig"}},"additionalProperties":false,"required":["job_uuid","training_config","hyperparam_search_config","logger_config"],"title":"SupervisedFineTuneRequest"}}},"required":true}}
>

</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"A PostTrainingJob.","content":{"application/json":{"schema":{"type":"object","properties":{"job_uuid":{"type":"string"}},"additionalProperties":false,"required":["job_uuid"],"title":"PostTrainingJob"}}}},"400":{"description":"The request was invalid or malformed","content":{"application/json":{"schema":{"type":"object","properties":{"status":{"type":"integer","description":"HTTP status code"},"title":{"type":"string","description":"Error title, a short summary of the error which is invariant for an error type"},"detail":{"type":"string","description":"Error detail, a longer human-readable description of the error"},"instance":{"type":"string","description":"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},"additionalProperties":false,"required":["status","title","detail"],"title":"Error","description":"Error response from the API. Roughly follows RFC 7807."},"example":{"status":400,"title":"Bad Request","detail":"The request was invalid or malformed"}}}},"429":{"description":"The client has sent too many requests in a given amount of time","content":{"application/json":{"schema":{"type":"object","properties":{"status":{"type":"integer","description":"HTTP status code"},"title":{"type":"string","description":"Error title, a short summary of the error which is invariant for an error type"},"detail":{"type":"string","description":"Error detail, a longer human-readable description of the error"},"instance":{"type":"string","description":"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},"additionalProperties":false,"required":["status","title","detail"],"title":"Error","description":"Error response from the API. Roughly follows RFC 7807."},"example":{"status":429,"title":"Too Many Requests","detail":"You have exceeded the rate limit. Please try again later."}}}},"500":{"description":"The server encountered an unexpected error","content":{"application/json":{"schema":{"type":"object","properties":{"status":{"type":"integer","description":"HTTP status code"},"title":{"type":"string","description":"Error title, a short summary of the error which is invariant for an error type"},"detail":{"type":"string","description":"Error detail, a longer human-readable description of the error"},"instance":{"type":"string","description":"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},"additionalProperties":false,"required":["status","title","detail"],"title":"Error","description":"Error response from the API. Roughly follows RFC 7807."},"example":{"status":500,"title":"Internal Server Error","detail":"An unexpected error occurred. Our team has been notified."}}}},"default":{"description":"An unexpected error occurred","content":{"application/json":{"schema":{"type":"object","properties":{"status":{"type":"integer","description":"HTTP status code"},"title":{"type":"string","description":"Error title, a short summary of the error which is invariant for an error type"},"detail":{"type":"string","description":"Error detail, a longer human-readable description of the error"},"instance":{"type":"string","description":"(Optional) A URL which can be used to retrieve more information about the specific occurrence of the error"}},"additionalProperties":false,"required":["status","title","detail"],"title":"Error","description":"Error response from the API. Roughly follows RFC 7807."},"example":{"status":0,"title":"Error","detail":"An unexpected error occurred"}}}}}}
>

</StatusCodes>
