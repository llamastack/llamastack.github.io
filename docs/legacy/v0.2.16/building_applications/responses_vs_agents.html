


<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Agents vs OpenAI Responses API &mdash; llama-stack 0.2.16 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/css/my_theme.css?v=f1163765" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/dark_mode_css/general.css?v=c0a7eb24" />
      <link rel="stylesheet" type="text/css" href="../_static/dark_mode_css/dark.css?v=70edf1c7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=e2418eca"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=09bf800d"></script>
      <script src="../_static/js/detect_theme.js?v=76226c80"></script>
      <script src="../_static/js/keyboard_shortcuts.js"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../_static/dark_mode_js/default_light.js?v=c2e647ce"></script>
      <script src="../_static/dark_mode_js/theme_switcher.js?v=358d3910"></script>
    <script src="../_static/js/theme.js"></script>
    <script src="../_static/js/versions.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tools" href="tools.html" />
    <link rel="prev" title="Agent Execution Loop" href="agent_execution_loop.html" />
 

<script src="../_static/version-loader.js"></script>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html" class="icon icon-home">
            llama-stack
          </a>
              <div class="switch-menus">
                <div class="version-switch"></div>
                <div class="language-switch"></div>
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Llama Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/index.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts/index.html">Core Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../providers/index.html">API Providers Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributions/index.html">Distributions Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_apis/index.html">Advanced APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">AI Application Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="rag.html">Retrieval Augmented Generation (RAG)</a></li>
<li class="toctree-l2"><a class="reference internal" href="agent.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="agent_execution_loop.html">Agent Execution Loop</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Agents vs OpenAI Responses API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#lls-agents-api">LLS Agents API</a></li>
<li class="toctree-l4"><a class="reference internal" href="#openai-responses-api">OpenAI Responses API</a></li>
<li class="toctree-l4"><a class="reference internal" href="#key-differences">Key Differences</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#use-case-example-research-with-multiple-search-methods">Use Case Example: Research with Multiple Search Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#agents-api-session-based-configuration-with-safety-shields">Agents API: Session-based configuration with safety shields</a></li>
<li class="toctree-l4"><a class="reference internal" href="#responses-api-dynamic-per-call-configuration-with-branching">Responses API: Dynamic per-call configuration with branching</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#use-case-examples">Use Case Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#research-and-analysis-with-safety-controls">1. <strong>Research and Analysis with Safety Controls</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#dynamic-information-gathering-with-branching-exploration">2. <strong>Dynamic Information Gathering with Branching Exploration</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#openai-migration-with-advanced-tool-capabilities">3. <strong>OpenAI Migration with Advanced Tool Capabilities</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#educational-programming-tutor">4. <strong>Educational Programming Tutor</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#advanced-software-debugging-assistant">5. <strong>Advanced Software Debugging Assistant</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#for-more-information">For More Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tools.html">Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="evals.html">Evaluations</a></li>
<li class="toctree-l2"><a class="reference internal" href="telemetry.html">Telemetry</a></li>
<li class="toctree-l2"><a class="reference internal" href="safety.html">Safety Guardrails</a></li>
<li class="toctree-l2"><a class="reference internal" href="playground/index.html">Llama Stack Playground</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deploying/index.html">Deployment Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributing to Llama-Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references/index.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">llama-stack</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">AI Application Examples</a></li>
      <li class="breadcrumb-item active">Agents vs OpenAI Responses API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/building_applications/responses_vs_agents.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="agents-vs-openai-responses-api">
<h1>Agents vs OpenAI Responses API<a class="headerlink" href="#agents-vs-openai-responses-api" title="Link to this heading"></a></h1>
<p>Llama Stack (LLS) provides two different APIs for building AI applications with tool calling capabilities: the <strong>Agents API</strong> and the <strong>OpenAI Responses API</strong>. While both enable AI systems to use tools, and maintain full conversation history, they serve different use cases and have distinct characteristics.</p>
<blockquote>
<div><p><strong>Note:</strong> For simple and basic inferencing, you may want to use the <a class="reference external" href="https://llama-stack.readthedocs.io/en/latest/providers/index.html#chat-completions">Chat Completions API</a> directly, before progressing to Agents or Responses API.</p>
</div></blockquote>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<section id="lls-agents-api">
<h3>LLS Agents API<a class="headerlink" href="#lls-agents-api" title="Link to this heading"></a></h3>
<p>The Agents API is a full-featured, stateful system designed for complex, multi-turn conversations. It maintains conversation state through persistent sessions identified by a unique session ID. The API supports comprehensive agent lifecycle management, detailed execution tracking, and rich metadata about each interaction through a structured session/turn/step hierarchy. The API can orchestrate multiple tool calls within a single turn.</p>
</section>
<section id="openai-responses-api">
<h3>OpenAI Responses API<a class="headerlink" href="#openai-responses-api" title="Link to this heading"></a></h3>
<p>The OpenAI Responses API is a full-featured, stateful system designed for complex, multi-turn conversations, with direct compatibility with OpenAI’s conversational patterns enhanced by LLama Stack’s tool calling capabilities. It maintains conversation state by chaining responses through a <code class="docutils literal notranslate"><span class="pre">previous_response_id</span></code>, allowing interactions to branch or continue from any prior point. Each response can perform multiple tool calls within a single turn.</p>
</section>
<section id="key-differences">
<h3>Key Differences<a class="headerlink" href="#key-differences" title="Link to this heading"></a></h3>
<p>The LLS Agents API uses the Chat Completions API on the backend for inference as it’s the industry standard for building AI applications and most LLM providers are compatible with this API. For a detailed comparison between Responses and Chat Completions, see <a class="reference external" href="https://platform.openai.com/docs/guides/responses-vs-chat-completions">OpenAI’s documentation</a>.</p>
<p>Additionally, Agents let you specify input/output shields whereas Responses do not (though support is planned). Agents use a linear conversation model referenced by a single session ID. Responses, on the other hand, support branching, where each response can serve as a fork point, and conversations are tracked by the latest response ID. Responses also lets you dynamically choose the model, vector store, files, MCP servers, and more on each inference call, enabling more complex workflows. Agents require a static configuration for these components at the start of the session.</p>
<p>Today the Agents and Responses APIs can be used independently depending on the use case. But, it is also productive to treat the APIs as complementary. It is not currently supported, but it is planned for the LLS Agents API to alternatively use the Responses API as its backend instead of the default Chat Completions API, i.e., enabling a combination of the safety features of Agents with the dynamic configuration and branching capabilities of Responses.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>LLS Agents API</p></th>
<th class="head"><p>OpenAI Responses API</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Conversation Management</strong></p></td>
<td><p>Linear persistent sessions</p></td>
<td><p>Can branch from any previous response ID</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Input/Output Safety Shields</strong></p></td>
<td><p>Supported</p></td>
<td><p>Not yet supported</p></td>
</tr>
<tr class="row-even"><td><p><strong>Per-call Flexibility</strong></p></td>
<td><p>Static per-session configuration</p></td>
<td><p>Dynamic per-call configuration</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="use-case-example-research-with-multiple-search-methods">
<h2>Use Case Example: Research with Multiple Search Methods<a class="headerlink" href="#use-case-example-research-with-multiple-search-methods" title="Link to this heading"></a></h2>
<p>Let’s compare how both APIs handle a research task where we need to:</p>
<ol class="arabic simple">
<li><p>Search for current information and examples</p></li>
<li><p>Access different information sources dynamically</p></li>
<li><p>Continue the conversation based on search results</p></li>
</ol>
<section id="agents-api-session-based-configuration-with-safety-shields">
<h3>Agents API: Session-based configuration with safety shields<a class="headerlink" href="#agents-api-session-based-configuration-with-safety-shields" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create agent with static session configuration</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">client</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Llama3.2-3B-Instruct&quot;</span><span class="p">,</span>
    <span class="n">instructions</span><span class="o">=</span><span class="s2">&quot;You are a helpful coding assistant&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;builtin::rag/knowledge_search&quot;</span><span class="p">,</span>
            <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;vector_db_ids&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;code_docs&quot;</span><span class="p">]},</span>
        <span class="p">},</span>
        <span class="s2">&quot;builtin::code_interpreter&quot;</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">input_shields</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;llama_guard&quot;</span><span class="p">],</span>
    <span class="n">output_shields</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;llama_guard&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">session_id</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">create_session</span><span class="p">(</span><span class="s2">&quot;code_session&quot;</span><span class="p">)</span>

<span class="c1"># First turn: Search and execute</span>
<span class="n">response1</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">create_turn</span><span class="p">(</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Find examples of sorting algorithms and run a bubble sort on [3,1,4,1,5]&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">session_id</span><span class="o">=</span><span class="n">session_id</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Continue conversation in same session</span>
<span class="n">response2</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">create_turn</span><span class="p">(</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Now optimize that code and test it with a larger dataset&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">session_id</span><span class="o">=</span><span class="n">session_id</span><span class="p">,</span>  <span class="c1"># Same session, maintains full context</span>
<span class="p">)</span>

<span class="c1"># Agents API benefits:</span>
<span class="c1"># ✅ Safety shields protect against malicious code execution</span>
<span class="c1"># ✅ Session maintains context between code executions</span>
<span class="c1"># ✅ Consistent tool configuration throughout conversation</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;First result: </span><span class="si">{</span><span class="n">response1</span><span class="o">.</span><span class="n">output_message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimization: </span><span class="si">{</span><span class="n">response2</span><span class="o">.</span><span class="n">output_message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="responses-api-dynamic-per-call-configuration-with-branching">
<h3>Responses API: Dynamic per-call configuration with branching<a class="headerlink" href="#responses-api-dynamic-per-call-configuration-with-branching" title="Link to this heading"></a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># First response: Use web search for latest algorithms</span>
<span class="n">response1</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Llama3.2-3B-Instruct&quot;</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Search for the latest efficient sorting algorithms and their performance comparisons&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;web_search&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">],</span>  <span class="c1"># Web search for current information</span>
<span class="p">)</span>

<span class="c1"># Continue conversation: Switch to file search for local docs</span>
<span class="n">response2</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Llama3.2-1B-Instruct&quot;</span><span class="p">,</span>  <span class="c1"># Switch to faster model</span>
    <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Now search my uploaded files for existing sorting implementations&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span>  <span class="c1"># Using Responses API built-in tools</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;file_search&quot;</span><span class="p">,</span>
            <span class="s2">&quot;vector_store_ids&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;vs_abc123&quot;</span><span class="p">],</span>  <span class="c1"># Vector store containing uploaded files</span>
        <span class="p">},</span>
    <span class="p">],</span>
    <span class="n">previous_response_id</span><span class="o">=</span><span class="n">response1</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Branch from first response: Try different search approach</span>
<span class="n">response3</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">responses</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Llama3.2-3B-Instruct&quot;</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Instead, search the web for Python-specific sorting best practices&quot;</span><span class="p">,</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;web_search&quot;</span><span class="p">}],</span>  <span class="c1"># Different web search query</span>
    <span class="n">previous_response_id</span><span class="o">=</span><span class="n">response1</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>  <span class="c1"># Branch from response1</span>
<span class="p">)</span>

<span class="c1"># Responses API benefits:</span>
<span class="c1"># ✅ Dynamic tool switching (web search ↔ file search per call)</span>
<span class="c1"># ✅ OpenAI-compatible tool patterns (web_search, file_search)</span>
<span class="c1"># ✅ Branch conversations to explore different information sources</span>
<span class="c1"># ✅ Model flexibility per search type</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Web search results: </span><span class="si">{</span><span class="n">response1</span><span class="o">.</span><span class="n">output_message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;File search results: </span><span class="si">{</span><span class="n">response2</span><span class="o">.</span><span class="n">output_message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Alternative web search: </span><span class="si">{</span><span class="n">response3</span><span class="o">.</span><span class="n">output_message</span><span class="o">.</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Both APIs demonstrate distinct strengths that make them valuable on their own for different scenarios. The Agents API excels in providing structured, safety-conscious workflows with persistent session management, while the Responses API offers flexibility through dynamic configuration and OpenAI compatible tool patterns.</p>
</section>
</section>
<section id="use-case-examples">
<h2>Use Case Examples<a class="headerlink" href="#use-case-examples" title="Link to this heading"></a></h2>
<section id="research-and-analysis-with-safety-controls">
<h3>1. <strong>Research and Analysis with Safety Controls</strong><a class="headerlink" href="#research-and-analysis-with-safety-controls" title="Link to this heading"></a></h3>
<p><strong>Best Choice: Agents API</strong></p>
<p><strong>Scenario:</strong> You’re building a research assistant for a financial institution that needs to analyze market data, execute code to process financial models, and search through internal compliance documents. The system must ensure all interactions are logged for regulatory compliance and protected by safety shields to prevent malicious code execution or data leaks.</p>
<p><strong>Why Agents API?</strong> The Agents API provides persistent session management for iterative research workflows, built-in safety shields to protect against malicious code in financial models, and structured execution logs (session/turn/step) required for regulatory compliance. The static tool configuration ensures consistent access to your knowledge base and code interpreter throughout the entire research session.</p>
</section>
<section id="dynamic-information-gathering-with-branching-exploration">
<h3>2. <strong>Dynamic Information Gathering with Branching Exploration</strong><a class="headerlink" href="#dynamic-information-gathering-with-branching-exploration" title="Link to this heading"></a></h3>
<p><strong>Best Choice: Responses API</strong></p>
<p><strong>Scenario:</strong> You’re building a competitive intelligence tool that helps businesses research market trends. Users need to dynamically switch between web search for current market data and file search through uploaded industry reports. They also want to branch conversations to explore different market segments simultaneously and experiment with different models for various analysis types.</p>
<p><strong>Why Responses API?</strong> The Responses API’s branching capability lets users explore multiple market segments from any research point. Dynamic per-call configuration allows switching between web search and file search as needed, while experimenting with different models (faster models for quick searches, more powerful models for deep analysis). The OpenAI-compatible tool patterns make integration straightforward.</p>
</section>
<section id="openai-migration-with-advanced-tool-capabilities">
<h3>3. <strong>OpenAI Migration with Advanced Tool Capabilities</strong><a class="headerlink" href="#openai-migration-with-advanced-tool-capabilities" title="Link to this heading"></a></h3>
<p><strong>Best Choice: Responses API</strong></p>
<p><strong>Scenario:</strong> You have an existing application built with OpenAI’s Assistants API that uses file search and web search capabilities. You want to migrate to Llama Stack for better performance and cost control while maintaining the same tool calling patterns and adding new capabilities like dynamic vector store selection.</p>
<p><strong>Why Responses API?</strong> The Responses API provides full OpenAI tool compatibility (<code class="docutils literal notranslate"><span class="pre">web_search</span></code>, <code class="docutils literal notranslate"><span class="pre">file_search</span></code>) with identical syntax, making migration seamless. The dynamic per-call configuration enables advanced features like switching vector stores per query or changing models based on query complexity - capabilities that extend beyond basic OpenAI functionality while maintaining compatibility.</p>
</section>
<section id="educational-programming-tutor">
<h3>4. <strong>Educational Programming Tutor</strong><a class="headerlink" href="#educational-programming-tutor" title="Link to this heading"></a></h3>
<p><strong>Best Choice: Agents API</strong></p>
<p><strong>Scenario:</strong> You’re building a programming tutor that maintains student context across multiple sessions, safely executes code exercises, and tracks learning progress with audit trails for educators.</p>
<p><strong>Why Agents API?</strong> Persistent sessions remember student progress across multiple interactions, safety shields prevent malicious code execution while allowing legitimate programming exercises, and structured execution logs help educators track learning patterns.</p>
</section>
<section id="advanced-software-debugging-assistant">
<h3>5. <strong>Advanced Software Debugging Assistant</strong><a class="headerlink" href="#advanced-software-debugging-assistant" title="Link to this heading"></a></h3>
<p><strong>Best Choice: Agents API with Responses Backend</strong></p>
<p><strong>Scenario:</strong> You’re building a debugging assistant that helps developers troubleshoot complex issues. It needs to maintain context throughout a debugging session, safely execute diagnostic code, switch between different analysis tools dynamically, and branch conversations to explore multiple potential causes simultaneously.</p>
<p><strong>Why Agents + Responses?</strong> The Agent provides safety shields for code execution and session management for the overall debugging workflow. The underlying Responses API enables dynamic model selection and flexible tool configuration per query, while branching lets you explore different theories (memory leak vs. concurrency issue) from the same debugging point and compare results.</p>
<blockquote>
<div><p><strong>Note:</strong> The ability to use Responses API as the backend for Agents is not yet implemented but is planned for a future release. Currently, Agents use Chat Completions API as their backend by default.</p>
</div></blockquote>
</section>
</section>
<section id="for-more-information">
<h2>For More Information<a class="headerlink" href="#for-more-information" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><strong>LLS Agents API</strong>: For detailed information on creating and managing agents, see the <a class="reference external" href="https://llama-stack.readthedocs.io/en/latest/building_applications/agent.html">Agents documentation</a></p></li>
<li><p><strong>OpenAI Responses API</strong>: For information on using the OpenAI-compatible responses API, see the <a class="reference external" href="https://platform.openai.com/docs/api-reference/responses">OpenAI API documentation</a></p></li>
<li><p><strong>Chat Completions API</strong>: For the default backend API used by Agents, see the <a class="reference external" href="https://llama-stack.readthedocs.io/en/latest/providers/index.html#chat-completions">Chat Completions providers documentation</a></p></li>
<li><p><strong>Agent Execution Loop</strong>: For understanding how agents process turns and steps in their execution, see the <a class="reference external" href="https://llama-stack.readthedocs.io/en/latest/building_applications/agent_execution_loop.html">Agent Execution Loop documentation</a></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="agent_execution_loop.html" class="btn btn-neutral float-left" title="Agent Execution Loop" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tools.html" class="btn btn-neutral float-right" title="Tools" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Meta.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Read the Docs</span>
    v: v0.2.16
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Versions</dt>
      <dd>
        <a href="/v0.2.19/">latest</a>
      </dd>
      <dd>
        <a href="/v0.2.19/">v0.2.19</a>
      </dd>
      <dd>
        <a href="/v0.2.18/">v0.2.18</a>
      </dd>
      <dd>
        <a href="/v0.2.17/">v0.2.17</a>
      </dd>
      <dd class="rtd-current-item">
        <a href="/v0.2.16/">v0.2.16</a>
      </dd>
      <dd>
        <a href="/v0.2.15/">v0.2.15</a>
      </dd>
      <dd>
        <a href="/v0.2.14/">v0.2.14</a>
      </dd>
      <dd>
        <a href="/v0.2.13/">v0.2.13</a>
      </dd>
      <dd>
        <a href="/v0.2.12/">v0.2.12</a>
      </dd>
      <dd>
        <a href="/v0.2.11/">v0.2.11</a>
      </dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>